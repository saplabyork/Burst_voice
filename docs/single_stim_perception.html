<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Single stim perception analysis</title>

<script src="site_libs/header-attrs-2.23/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="shortcut icon" href="images/logo.jpeg">

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">BurstVoice</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Background</a>
</li>
<li>
  <a href="measurements.html">Acoustics methods</a>
</li>
<li>
  <a href="Practice.html">Practice</a>
</li>
<li>
  <a href="data_anal.html">Data Production</a>
</li>
<li>
  <a href="single_stim_perception.html">Data Perception</a>
</li>
<li>
  <a href="notes.html">Notes</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Single stim perception analysis</h1>

</div>


<style type="text/css">
  body{
  font-size: 12pt;
}
</style>
<style type="text/css">
.title {
  display: none;
}

#getting-started img {
  margin-right: 10px;
}

</style>
<pre class="r"><code>per_data &lt;- read.csv(&quot;/Users/chandannarayan/GitHub/Burst_voice/Data/Master_Single_stim_long.csv&quot;, header=TRUE)

number_of_subs &lt;- length(unique(per_data$sub))
number_of_subs</code></pre>
<pre><code>## [1] 20</code></pre>
<pre class="r"><code>library(lme4)</code></pre>
<pre><code>## Warning: package &#39;lme4&#39; was built under R version 4.3.3</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre class="r"><code>library(ggplot2)
library(ggeffects)</code></pre>
<pre><code>## Warning: package &#39;ggeffects&#39; was built under R version 4.3.3</code></pre>
<pre class="r"><code>per_data$ons_con &lt;- as.factor(per_data$ons_con)

#per_data_cor &lt;- subset(per_data, Correct==&quot;1&quot;)

library(tidyverse)</code></pre>
<pre><code>## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
## ✔ dplyr     1.1.4     ✔ readr     2.1.4
## ✔ forcats   1.0.0     ✔ stringr   1.5.0
## ✔ lubridate 1.9.3     ✔ tibble    3.2.1
## ✔ purrr     1.0.2     ✔ tidyr     1.3.0</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ tidyr::expand() masks Matrix::expand()
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()
## ✖ tidyr::pack()   masks Matrix::pack()
## ✖ tidyr::unpack() masks Matrix::unpack()
## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
<pre class="r"><code># Create a crosstab table with ons_con on rows, stim_length on columns
# with marginal totals for each row and column

crosstab_table &lt;- per_data %&gt;%
  group_by(ons_con, stim_length) %&gt;%
  summarise(
    percent_correct = mean(Correct) * 100,
    n = n(),
    .groups = &quot;drop&quot;
  ) %&gt;%
  # Add formatted column combining percentage and n
  mutate(formatted = paste0(round(percent_correct, 1), &quot;%\n(n=&quot;, n, &quot;)&quot;)) %&gt;%
  select(ons_con, stim_length, formatted) %&gt;%
  # Pivot wider to get stim_length as columns
  pivot_wider(names_from = stim_length, values_from = formatted)

# Calculate row totals (marginal totals for each ons_con)
row_totals &lt;- per_data %&gt;%
  group_by(ons_con) %&gt;%
  summarise(
    percent_correct = mean(Correct) * 100,
    n = n(),
    .groups = &quot;drop&quot;
  ) %&gt;%
  mutate(Total = paste0(round(percent_correct, 1), &quot;%\n(n=&quot;, n, &quot;)&quot;)) %&gt;%
  select(ons_con, Total)

# Calculate column totals (marginal totals for each stim_length)
col_totals &lt;- per_data %&gt;%
  group_by(stim_length) %&gt;%
  summarise(
    percent_correct = mean(Correct) * 100,
    n = n(),
    .groups = &quot;drop&quot;
  ) %&gt;%
  mutate(formatted = paste0(round(percent_correct, 1), &quot;%\n(n=&quot;, n, &quot;)&quot;)) %&gt;%
  select(stim_length, formatted) %&gt;%
  pivot_wider(names_from = stim_length, values_from = formatted) %&gt;%
  mutate(ons_con = &quot;Total&quot;)

# Calculate overall total
overall_total &lt;- per_data %&gt;%
  summarise(
    percent_correct = mean(Correct) * 100,
    n = n()
  ) %&gt;%
  mutate(Total = paste0(round(percent_correct, 1), &quot;%\n(n=&quot;, n, &quot;)&quot;)) %&gt;%
  pull(Total)

# Add row totals to the main table
final_table &lt;- crosstab_table %&gt;%
  left_join(row_totals, by = &quot;ons_con&quot;)

# Add column totals row
col_totals_row &lt;- col_totals %&gt;%
  mutate(Total = overall_total)

# Combine everything
complete_table &lt;- bind_rows(
  final_table,
  col_totals_row
)

# Display the table
print(complete_table)</code></pre>
<pre><code>## # A tibble: 3 × 4
##   ons_con long             short            Total           
##   &lt;chr&gt;   &lt;chr&gt;            &lt;chr&gt;            &lt;chr&gt;           
## 1 k       &quot;41.7%\n(n=120)&quot; &quot;83%\n(n=100)&quot;   &quot;60.5%\n(n=220)&quot;
## 2 p       &quot;40%\n(n=120)&quot;   &quot;65.7%\n(n=140)&quot; &quot;53.8%\n(n=260)&quot;
## 3 Total   &quot;40.8%\n(n=240)&quot; &quot;72.9%\n(n=240)&quot; &quot;56.9%\n(n=480)&quot;</code></pre>
<pre class="r"><code># Alternative: Create a cleaner version without the \n formatting
clean_table &lt;- per_data %&gt;%
  group_by(ons_con, stim_length) %&gt;%
  summarise(
    percent_correct = round(mean(Correct) * 100, 1),
    .groups = &quot;drop&quot;
  ) %&gt;%
  pivot_wider(names_from = stim_length, values_from = percent_correct) %&gt;%
  # Add row totals
  left_join(
    per_data %&gt;%
      group_by(ons_con) %&gt;%
      summarise(Total = round(mean(Correct) * 100, 1), .groups = &quot;drop&quot;),
    by = &quot;ons_con&quot;
  )

# Add column totals
col_totals_clean &lt;- per_data %&gt;%
  group_by(stim_length) %&gt;%
  summarise(percent_correct = round(mean(Correct) * 100, 1), .groups = &quot;drop&quot;) %&gt;%
  pivot_wider(names_from = stim_length, values_from = percent_correct) %&gt;%
  mutate(
    ons_con = &quot;Total&quot;,
    Total = round(mean(per_data$Correct) * 100, 1)
  )

clean_complete_table &lt;- bind_rows(clean_table, col_totals_clean)

print(&quot;\nClean version (percentages only):&quot;)</code></pre>
<pre><code>## [1] &quot;\nClean version (percentages only):&quot;</code></pre>
<pre class="r"><code>print(clean_complete_table)</code></pre>
<pre><code>## # A tibble: 3 × 4
##   ons_con  long short Total
##   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 k        41.7  83    60.5
## 2 p        40    65.7  53.8
## 3 Total    40.8  72.9  56.9</code></pre>
<pre class="r"><code># Fit the mixed-effects logistic regression model with interaction term
per_model &lt;- glmer(response_vc ~ stim_length * ons_con + (1 | vowel) + (1 | sub), 
                   data = per_data, 
                   family = binomial)

summary(per_model)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: response_vc ~ stim_length * ons_con + (1 | vowel) + (1 | sub)
##    Data: per_data
## 
##      AIC      BIC   logLik deviance df.resid 
##    602.5    627.5   -295.2    590.5      474 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.0738 -0.7482 -0.5433  1.0769  2.8240 
## 
## Random effects:
##  Groups Name        Variance Std.Dev.
##  sub    (Intercept) 0.08612  0.2935  
##  vowel  (Intercept) 0.08179  0.2860  
## Number of obs: 480, groups:  sub, 20; vowel, 3
## 
## Fixed effects:
##                           Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)               -0.34975    0.25923  -1.349   0.1773    
## stim_lengthshort          -1.29401    0.32965  -3.925 8.66e-05 ***
## ons_conp                  -0.07167    0.26747  -0.268   0.7888    
## stim_lengthshort:ons_conp  1.04443    0.42162   2.477   0.0132 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) stm_ln ons_cn
## stm_lngthsh -0.413              
## ons_conp    -0.513  0.404       
## stm_lngth:_  0.323 -0.783 -0.635</code></pre>
<pre class="r"><code># Fully crossed model with random slopes/intercepts
per_model_full &lt;- glmer(response_vc ~ stim_length * ons_con + (1 + stim_length + ons_con | sub), 
                   data = per_data, 
                   family = binomial, control=glmerControl(optimizer=&quot;bobyqa&quot;,
                            optCtrl=list(maxfun=2e5)))</code></pre>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre class="r"><code>summary(per_model_full)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: response_vc ~ stim_length * ons_con + (1 + stim_length + ons_con |  
##     sub)
##    Data: per_data
## Control: glmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05))
## 
##      AIC      BIC   logLik deviance df.resid 
##    609.5    651.2   -294.7    589.5      470 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.1118 -0.7360 -0.4977  1.0950  2.3319 
## 
## Random effects:
##  Groups Name             Variance Std.Dev. Corr       
##  sub    (Intercept)      0.27609  0.5254              
##         stim_lengthshort 0.67610  0.8223   -0.97      
##         ons_conp         0.02921  0.1709    0.94 -0.82
## Number of obs: 480, groups:  sub, 20
## 
## Fixed effects:
##                           Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)               -0.35298    0.22445  -1.573   0.1158   
## stim_lengthshort          -1.25801    0.38235  -3.290   0.0010 **
## ons_conp                  -0.08651    0.27690  -0.312   0.7547   
## stim_lengthshort:ons_conp  1.02827    0.42750   2.405   0.0162 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) stm_ln ons_cn
## stm_lngthsh -0.671              
## ons_conp    -0.519  0.293       
## stm_lngth:_  0.382 -0.681 -0.638
## optimizer (bobyqa) convergence code: 0 (OK)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre class="r"><code># Singularity problem with random effects structure, so random slopes/intercepts for just one variable

per_model_full &lt;- glmer(response_vc ~ stim_length * ons_con + (1 + stim_length | sub), 
                   data = per_data, 
                   family = binomial, control=glmerControl(optimizer=&quot;bobyqa&quot;,
                            optCtrl=list(maxfun=2e5)))

summary(per_model_full)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: response_vc ~ stim_length * ons_con + (1 + stim_length | sub)
##    Data: per_data
## Control: glmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05))
## 
##      AIC      BIC   logLik deviance df.resid 
##    603.9    633.1   -294.9    589.9      473 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.0729 -0.7333 -0.4820  1.1014  2.2931 
## 
## Random effects:
##  Groups Name             Variance Std.Dev. Corr 
##  sub    (Intercept)      0.3554   0.5961        
##         stim_lengthshort 0.6303   0.7939   -0.95
## Number of obs: 480, groups:  sub, 20
## 
## Fixed effects:
##                           Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)               -0.35682    0.23441  -1.522 0.127947    
## stim_lengthshort          -1.24836    0.37823  -3.301 0.000965 ***
## ons_conp                  -0.07473    0.27306  -0.274 0.784325    
## stim_lengthshort:ons_conp  1.00880    0.42346   2.382 0.017206 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) stm_ln ons_cn
## stm_lngthsh -0.673              
## ons_conp    -0.578  0.358       
## stm_lngth:_  0.373 -0.685 -0.645</code></pre>
<pre class="r"><code># Generate predicted probabilities
per_data$predicted &lt;- predict(per_model_full, type = &quot;response&quot;)  # Predicted probabilities

# Summarize predicted probabilities by `stim_length` and `ons_con`
summary_df &lt;- aggregate(predicted ~ stim_length + ons_con, data = per_data, 
                        FUN = function(x) c(mean = mean(x), se = sd(x)/sqrt(length(x))))

# Unpack the summary into a new data frame
summary_df &lt;- do.call(data.frame, summary_df)
colnames(summary_df) &lt;- c(&quot;stim_length&quot;, &quot;ons_con&quot;, &quot;mean_prob&quot;, &quot;se_prob&quot;)

# Compute confidence intervals
summary_df$lower_ci &lt;- summary_df$mean_prob - 1.96 * summary_df$se_prob
summary_df$upper_ci &lt;- summary_df$mean_prob + 1.96 * summary_df$se_prob

# Plot the results with facets for ons_con
ggplot(summary_df, aes(x = stim_length, y = mean_prob)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) +
  facet_wrap(~ons_con) +  # Create separate facets for each level of ons_con
  scale_y_continuous(limits = c(0.1, 0.5)) +  # Set y-axis limits from 0.1 to 0.5
  labs(#title = &quot;Predicted Probabilities by Stimulus Length and Onset Consonant&quot;,
       x = &quot;Onset VOT Length&quot;,
       y = &quot;Predicted Probability of Voiced Coda&quot;) +
  theme_bw(base_size = 12)</code></pre>
<p><img src="single_stim_perception_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code># Plot the results with color-coded ons_con
ggplot(summary_df, aes(x = stim_length, y = mean_prob, color = ons_con)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) +
  scale_y_continuous(limits = c(0.1, 0.6)) +  # Set y-axis limits from 0 to 1
  labs(title = &quot;Predicted Probabilities by Stimulus Length and Onset Consonant&quot;,
       x = &quot;VOT Length&quot;,
       y = &quot;Predicted Probability of Voiced Coda&quot;,
       color = &quot;Onset Consonant&quot;) +
  theme_minimal()</code></pre>
<p><img src="single_stim_perception_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<pre class="r"><code>###

# Install ggeffects if not already installed
install.packages(&quot;ggeffects&quot;)</code></pre>
<pre><code>## 
## The downloaded binary packages are in
##  /var/folders/nv/72l7lgjs2s5d2y6bbl5wz6w40000gn/T//RtmpOfvDYg/downloaded_packages</code></pre>
<pre class="r"><code># Load the package
library(ggeffects)

# Generate predicted probabilities for `stim_length`
probabilities &lt;- ggpredict(per_model, terms = &quot;stim_length&quot;)</code></pre>
<pre><code>## You are calculating adjusted predictions on the population-level (i.e.
##   `type = &quot;fixed&quot;`) for a *generalized* linear mixed model.
##   This may produce biased estimates due to Jensen&#39;s inequality. Consider
##   setting `bias_correction = TRUE` to correct for this bias.
##   See also the documentation of the `bias_correction` argument.</code></pre>
<pre class="r"><code># Print the probabilities
print(probabilities)</code></pre>
<pre><code>## # Predicted probabilities of response_vc
## 
## stim_length | Predicted |     95% CI
## ------------------------------------
## long        |      0.41 | 0.30, 0.54
## short       |      0.16 | 0.09, 0.27
## 
## Adjusted for:
## * ons_con = k
## *   vowel = 0 (population-level)
## *     sub = 0 (population-level)</code></pre>
<pre class="r"><code># Plot the probabilities
plot(probabilities)</code></pre>
<p><img src="single_stim_perception_files/figure-html/unnamed-chunk-1-3.png" width="672" /></p>
<pre class="r"><code># Install if needed
# install.packages(&quot;brms&quot;)

# Trying out Bayes

library(brms)</code></pre>
<pre><code>## Warning: package &#39;brms&#39; was built under R version 4.3.3</code></pre>
<pre><code>## Loading required package: Rcpp</code></pre>
<pre><code>## Loading &#39;brms&#39; package (version 2.22.0). Useful instructions
## can be found by typing help(&#39;brms&#39;). A more detailed introduction
## to the package is available through vignette(&#39;brms_overview&#39;).</code></pre>
<pre><code>## 
## Attaching package: &#39;brms&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:lme4&#39;:
## 
##     ngrps</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     ar</code></pre>
<pre class="r"><code>per_model_bayes &lt;- brm(response_vc ~ stim_length * ons_con + (1 + stim_length | sub), 
                       data = per_data, 
                       family = bernoulli(),
                       chains = 4,
                       iter = 2000,
                       cores = 4)</code></pre>
<pre><code>## Compiling Stan program...</code></pre>
<pre><code>## Trying to compile a simple C file</code></pre>
<pre><code>## Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c
## using C compiler: ‘Apple clang version 12.0.5 (clang-1205.0.22.9)’
## using SDK: ‘MacOSX11.3.sdk’
## clang -arch arm64 -I&quot;/Library/Frameworks/R.framework/Resources/include&quot; -DNDEBUG   -I&quot;/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/Rcpp/include/&quot;  -I&quot;/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/RcppEigen/include/&quot;  -I&quot;/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/RcppEigen/include/unsupported&quot;  -I&quot;/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/BH/include&quot; -I&quot;/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/StanHeaders/include/src/&quot;  -I&quot;/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/StanHeaders/include/&quot;  -I&quot;/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/RcppParallel/include/&quot;  -I&quot;/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/rstan/include&quot; -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include &#39;/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp&#39;  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o
## In file included from &lt;built-in&gt;:1:
## In file included from /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
## In file included from /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/RcppEigen/include/Eigen/Dense:1:
## In file included from /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/RcppEigen/include/Eigen/Core:19:
## /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: &#39;cmath&#39; file not found
## #include &lt;cmath&gt;
##          ^~~~~~~
## 1 error generated.
## make: *** [foo.o] Error 1</code></pre>
<pre><code>## Start sampling</code></pre>
<pre class="r"><code># Check the model
summary(per_model_bayes)</code></pre>
<pre><code>##  Family: bernoulli 
##   Links: mu = logit 
## Formula: response_vc ~ stim_length * ons_con + (1 + stim_length | sub) 
##    Data: per_data (Number of observations: 480) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Multilevel Hyperparameters:
## ~sub (Number of levels: 20) 
##                                 Estimate Est.Error l-95% CI u-95% CI Rhat
## sd(Intercept)                       0.53      0.25     0.07     1.05 1.01
## sd(stim_lengthshort)                0.75      0.39     0.08     1.54 1.01
## cor(Intercept,stim_lengthshort)    -0.61      0.40    -0.99     0.57 1.01
##                                 Bulk_ESS Tail_ESS
## sd(Intercept)                        936     1435
## sd(stim_lengthshort)                 854     1347
## cor(Intercept,stim_lengthshort)     1307     1726
## 
## Regression Coefficients:
##                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept                    -0.35      0.23    -0.82     0.09 1.00     2910
## stim_lengthshort             -1.32      0.39    -2.11    -0.56 1.00     2102
## ons_conp                     -0.08      0.27    -0.60     0.46 1.00     3570
## stim_lengthshort:ons_conp     1.05      0.43     0.20     1.92 1.00     2832
##                           Tail_ESS
## Intercept                     2832
## stim_lengthshort              2230
## ons_conp                      3120
## stim_lengthshort:ons_conp     2880
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>plot(per_model_bayes)</code></pre>
<p><img src="single_stim_perception_files/figure-html/unnamed-chunk-2-1.png" width="672" /><img src="single_stim_perception_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<pre class="r"><code># Check the coding of stim_length
table(per_data$stim_length)</code></pre>
<pre><code>## 
##  long short 
##   240   240</code></pre>
<pre class="r"><code>levels(factor(per_data$stim_length))</code></pre>
<pre><code>## [1] &quot;long&quot;  &quot;short&quot;</code></pre>
<pre class="r"><code># Check what the reference level is
contrasts(factor(per_data$stim_length))</code></pre>
<pre><code>##       short
## long      0
## short     1</code></pre>
<pre class="r"><code>## Get the actual probabilities from the model

# Extract coefficients
fixef(per_model_bayes)</code></pre>
<pre><code>##                              Estimate Est.Error       Q2.5       Q97.5
## Intercept                 -0.35429130 0.2292038 -0.8210301  0.08957377
## stim_lengthshort          -1.32221016 0.3876718 -2.1103305 -0.56499787
## ons_conp                  -0.07580756 0.2708458 -0.5987907  0.45607734
## stim_lengthshort:ons_conp  1.05230561 0.4306577  0.1950215  1.91700803</code></pre>
<pre class="r"><code># For long stimuli, ons_con at reference level:
intercept &lt;- -0.34
prob_long_ref &lt;- plogis(intercept)  # plogis converts log-odds to probability
prob_long_ref  # Should be around 0.42</code></pre>
<pre><code>## [1] 0.4158095</code></pre>
<pre class="r"><code># For short stimuli, ons_con at reference level:
prob_short_ref &lt;- plogis(intercept + (-1.34))
prob_short_ref  # Should be around 0.17</code></pre>
<pre><code>## [1] 0.1570955</code></pre>
<pre class="r"><code># For long stimuli, ons_con = &quot;p&quot;:
prob_long_p &lt;- plogis(intercept + (-0.08))
prob_long_p</code></pre>
<pre><code>## [1] 0.3965168</code></pre>
<pre class="r"><code># For short stimuli, ons_con = &quot;p&quot;:
prob_short_p &lt;- plogis(intercept + (-1.34) + (-0.08) + 1.07)
prob_short_p</code></pre>
<pre><code>## [1] 0.3340331</code></pre>
<pre class="r"><code># Load required libraries
library(brms)
library(ggplot2)
library(dplyr)
library(tidyr)

# Create a grid of predictor values to get estimates for each condition
# Get unique values of your predictors
stim_lengths &lt;- unique(per_data$stim_length)
ons_cons &lt;- unique(per_data$ons_con)

# Create prediction grid
pred_grid &lt;- expand.grid(
  stim_length = stim_lengths,
  ons_con = ons_cons
)

# Get posterior predictions for each condition
# Get the full posterior draws first
posterior_draws &lt;- posterior_epred(per_model_bayes, 
                                  newdata = pred_grid,
                                  allow_new_levels = TRUE,
                                  re_formula = NA)  # This marginalizes over random effects

# Calculate summary statistics manually
posterior_summary &lt;- apply(posterior_draws, 2, function(x) {
  c(estimate = mean(x),
    lower = quantile(x, 0.025),
    upper = quantile(x, 0.975))
})

# Combine predictions with the grid
plot_data &lt;- pred_grid %&gt;%
  mutate(
    estimate = posterior_summary[1, ],
    lower = posterior_summary[2, ],
    upper = posterior_summary[3, ]
  )

# Create the plot
ggplot(plot_data, aes(x = factor(ons_con, levels = c(&quot;p&quot;, &quot;k&quot;)), y = estimate, color = factor(stim_length))) +
  geom_point(size = 3, position = position_dodge(width = 0.1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), 
                width = 0.05, 
                size = 1,
                position = position_dodge(width = 0.1)) +
  labs(
    title = &quot;Bayesian Model Estimates by Stimulus Length and Onset Condition&quot;,
    x = &quot;Onset Condition&quot;,
    y = &quot;Predicted probability of a perceived VOICED coda&quot;,
    color = &quot;Stimulus Length&quot;
  ) +
  theme_minimal() +
  theme(
    legend.position = &quot;bottom&quot;,
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 12),
    legend.text = element_text(size = 11),
    panel.grid.major = element_line(color = &quot;grey90&quot;, size = 0.5),
    panel.grid.minor = element_line(color = &quot;grey95&quot;, size = 0.3)
  ) +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent_format())</code></pre>
<pre><code>## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.</code></pre>
<pre><code>## Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.
## ℹ Please use the `linewidth` argument instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.</code></pre>
<p><img src="single_stim_perception_files/figure-html/unnamed-chunk-2-3.png" width="672" /></p>
<pre class="r"><code># Alternative version with different styling
ggplot(plot_data, aes(x = factor(ons_con, levels = c(&quot;p&quot;, &quot;k&quot;)), y = estimate, color = factor(stim_length))) +
  geom_point(size = 4, position = position_dodge(width = 0.3)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), 
                width = 0.2, 
                size = 1.2,
                position = position_dodge(width = 0.3)) +
  labs(
    title = &quot;Model Estimates with 95% Credible Intervals&quot;,
    x = &quot;Onset&quot;,
    y = &quot;Predicted probability of a perceived VOICED coda&quot;,
    color = &quot;Stimulus Length&quot;
  ) +
  theme_classic() +
  theme(
    legend.position = &quot;right&quot;,
    plot.title = element_text(hjust = 0.5, size = 16, face = &quot;bold&quot;),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    legend.title = element_text(size = 12, face = &quot;bold&quot;),
    legend.text = element_text(size = 11),
    panel.grid.major = element_line(color = &quot;grey90&quot;, size = 0.5),
    panel.grid.minor = element_line(color = &quot;grey95&quot;, size = 0.3)
  ) +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent_format())</code></pre>
<p><img src="single_stim_perception_files/figure-html/unnamed-chunk-2-4.png" width="672" /></p>
<pre class="r"><code># If you want to see the actual data values used:
print(&quot;Prediction grid and estimates:&quot;)</code></pre>
<pre><code>## [1] &quot;Prediction grid and estimates:&quot;</code></pre>
<pre class="r"><code>print(plot_data)</code></pre>
<pre><code>##   stim_length ons_con  estimate      lower     upper
## 1       short       k 0.1618668 0.08933999 0.2472333
## 2        long       k 0.4134481 0.30554504 0.5223785
## 3       short       p 0.3337484 0.23818972 0.4379903
## 4        long       p 0.3954227 0.29113699 0.5036658</code></pre>
<div id="how-to-interpret-the-model-and-plot" class="section level1">
<h1>How to interpret the model and plot?</h1>
<p>The negative coefficient for stim_lengthshort (-1.33) means that
short stimulus length decreases the probability that response_vc = 1 In
other words: long stimuli have higher probability of voiced coda
perception than short stimuli</p>
<p>This matches your plot perfectly - you can see that the points for
long stimuli (one color) are higher on the y-axis than the points for
short stimuli (other color) for both onset conditions. In practical
terms:</p>
<p>Long stimuli → higher probability of perceiving a voiced coda Short
stimuli → lower probability of perceiving a voiced coda The interaction
shows this length effect is stronger for /k/ onsets than /p/ onsets</p>
</div>
<div id="key-diagnostics-you-should-report" class="section level1">
<h1>Key diagnostics you should report:</h1>
<pre class="r"><code># # Load required libraries
# library(brms)        # Load brms first
# library(ggplot2)
# library(bayesplot)   # Load bayesplot after brms
# rhat &lt;- brms::rhat
# 
# # 1. CONVERGENCE DIAGNOSTICS (Most Important)
# # Check Rhat values (should be &lt; 1.01, ideally &lt; 1.001)
# rhat_values &lt;- rhat(per_model_bayes)
# print(&quot;Rhat values:&quot;)
# print(rhat_values)
# 
# # Check effective sample sizes
# #ess_bulk &lt;- neff_ratio(per_model_bayes)
# # For tail ESS, check the summary or use posterior package
# # Check convergence diagnostics
# summary(per_model_bayes)  # This shows Bulk_ESS and Tail_ESS in the output
# model_summary &lt;- summary(per_model_bayes)
# print(&quot;Effective Sample Size ratios (should be &gt; 0.1):&quot;)
# print(paste(&quot;Bulk ESS ratio range:&quot;, round(min(ess_bulk), 3), &quot;to&quot;, round(max(ess_bulk), 3)))
# print(paste(&quot;Tail ESS ratio range:&quot;, round(min(ess_tail), 3), &quot;to&quot;, round(max(ess_tail), 3)))
# 
# # 2. TRACE PLOTS (Visual convergence check)
# plot(per_model_bayes, pars = c(&quot;b_Intercept&quot;, &quot;b_stim_lengthshort&quot;, 
#                                &quot;b_ons_conp&quot;, &quot;b_stim_lengthshort:ons_conp&quot;))
# 
# # 3. POSTERIOR PREDICTIVE CHECKS
# # Check if model reproduces key patterns in the data
# pp_check(per_model_bayes, ndraws = 100)
# 
# # More specific posterior predictive checks
# pp_check(per_model_bayes, type = &quot;bars&quot;, ndraws = 500)  # For binary data
# pp_check(per_model_bayes, type = &quot;stat&quot;, stat = &quot;mean&quot;, ndraws = 1000)
# pp_check(per_model_bayes, type = &quot;stat_grouped&quot;, 
#          stat = &quot;mean&quot;, group = &quot;stim_length&quot;, ndraws = 500)
# 
# # 4. MODEL COMPARISON (if you have alternative models)
# # Example: Compare to simpler models
# # per_model_simple &lt;- brm(response_vc ~ stim_length + ons_con + (1|sub), 
# #                        data = per_data, family = bernoulli())
# # loo_compare(loo(per_model_bayes), loo(per_model_simple))
# 
# # 5. RESIDUAL DIAGNOSTICS
# # For mixed effects models, check residuals at different levels
# residuals_plot &lt;- plot(per_model_bayes, type = &quot;residuals&quot;)
# print(residuals_plot)
# 
# # 6. RANDOM EFFECTS DIAGNOSTICS
# # Check if random effects are reasonable
# plot(per_model_bayes, pars = &quot;^r_sub&quot;)
# 
# # Check random effects correlations
# plot(per_model_bayes, pars = &quot;cor&quot;)
# 
# # 7. MCMC DIAGNOSTICS
# # Check for divergent transitions
# nuts_params &lt;- nuts_params(per_model_bayes)
# print(&quot;Number of divergent transitions:&quot;)
# sum(subset(nuts_params, Parameter == &quot;divergent__&quot;)$Value)
# 
# # Energy diagnostics
# mcmc_nuts_energy(nuts_params)
# 
# # 8. MODEL SUMMARY FOR REPORTING
# print(&quot;=== MODEL SUMMARY FOR REPORTING ===&quot;)
# summary(per_model_bayes)
# 
# # 9. LEAVE-ONE-OUT CROSS-VALIDATION
# loo_result &lt;- loo(per_model_bayes)
# print(loo_result)
# 
# # Check for problematic observations
# plot(loo_result)
# 
# # 10. PRIOR-POSTERIOR COMPARISON (if you set informative priors)
# # Check if priors were reasonable
# prior_summary(per_model_bayes)
# 
# # 11. R-SQUARED (Bayesian version)
# bayes_R2(per_model_bayes)
# 
# # 12. WHAT TO REPORT IN YOUR PAPER
# cat(&quot;
# === DIAGNOSTICS TO REPORT ===
# 
# 1. CONVERGENCE:
#    - All Rhat values &lt; 1.01 (report range)
#    - Effective sample sizes &gt; 400 for all parameters
#    - No divergent transitions
#    
# 2. MODEL FIT:
#    - Posterior predictive checks show model reproduces data patterns
#    - LOO-CV information criterion for model comparison
#    - Bayesian R-squared for explained variance
#    
# 3. SAMPLE DESCRIPTION:
#    - 4 chains, 2000 iterations each (1000 warmup)
#    - Total of 4000 post-warmup draws
#    - MCMC sampling using NUTS algorithm
# 
# Example text for methods:
# &#39;Model convergence was assessed using Rhat statistics (all &lt; 1.01) 
# and effective sample sizes (all &gt; 400). Posterior predictive checks 
# confirmed the model adequately reproduced the observed data patterns. 
# No divergent transitions were observed during sampling.&#39;
# &quot;)
# 
# # 13. SPECIFIC CHECKS FOR YOUR MODEL
# # Check interaction effects visually
# marginal_effects(per_model_bayes, effects = &quot;stim_length:ons_con&quot;)
# 
# # Check if random effects structure is justified
# # Compare models with/without random slopes
# # This helps justify the complexity of your random effects</code></pre>
<ol style="list-style-type: decimal">
<li>Convergence (Essential)</li>
</ol>
<p>Rhat &lt; 1.01 for all parameters (yours look good: all ≈ 1.00)
Effective sample sizes &gt; 400 (yours are excellent: 862-4104) No
divergent transitions</p>
<ol start="2" style="list-style-type: decimal">
<li>Model Fit</li>
</ol>
<p>Posterior predictive checks (pp_check()) - shows if model reproduces
data patterns LOO cross-validation for model comparison Bayesian R² for
explained variance</p>
<ol start="3" style="list-style-type: decimal">
<li>What to report in your paper: “Model convergence was assessed using
R̂ statistics (all &lt; 1.01, range: 1.00-1.01) and effective sample
sizes (all &gt; 400, range: 862-4104). Posterior predictive checks
confirmed adequate model fit to the observed data. MCMC sampling used 4
chains with 2000 iterations each (1000 warmup), yielding 4000
post-warmup draws with no divergent transitions.” Your model already
shows excellent diagnostics:</li>
</ol>
<p>Perfect Rhat values (all 1.00-1.01) High effective sample sizes Good
mixing indicated by the diagnostics</p>
<p>The most important ones to run and report are the convergence checks
(which you already have) and posterior predictive checks to show your
model actually fits the data well.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
